{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 버전 기록_FULL\n",
    "- Model Baseline 코드 (2024.12.30)\n",
    "- Drug Graph, Drug Graph Embedding Block 추가 (2025.01.01)\n",
    "- Train, Valid, Test 추가 (25.01.02)\n",
    "- Pathway Graph, Pathway Graph Embedding Block 추가 (2025.01.03)\n",
    "- 연산 최적화, 모델 내 for문 제거, 텐서 연산 활용 (2025.01.04)\n",
    "- Train, Valid, Test 데이터셋 pt 파일 저장 (2025.01.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cell_lines = 1280\n",
    "num_pathways = 314\n",
    "num_genes = 3848\n",
    "num_drugs = 83\n",
    "num_substructures = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugResponseDataset(Dataset):\n",
    "    def __init__(self, gene_embeddings, pathway_graphs, substructure_embeddings, drug_graphs, labels, sample_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gene_embeddings (dict): {cell_line_id: Tensor}, Gene embeddings for each cell line.\n",
    "            drug_graphs (dict): List of PyTorch Geometric Data objects for each drug (indexed by drug_id).\n",
    "            substructure_embeddings (Tensor): [245, 193], Substructure embeddings for pathways.\n",
    "            labels (dict): {cell_line_id: Tensor}, Drug response labels for each cell line and drug pair.\n",
    "            sample_indices (list): [(cell_line_id, drug_idx)], List of cell line and drug index pairs.\n",
    "        \"\"\"\n",
    "        self.gene_embeddings = gene_embeddings  # {cell_line_id: [245, 231]}\n",
    "        self.pathway_graphs = pathway_graphs\n",
    "        self.drug_graphs = drug_graphs  # Drug graphs\n",
    "        self.substructure_embeddings = substructure_embeddings  # [170]\n",
    "        self.labels = labels  # {cell_line_id, drug_id : [1]}\n",
    "        self.sample_indices = sample_indices  # [(cell_line_id, drug_id)]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cell_line_id, drug_id = self.sample_indices[idx]\n",
    "\n",
    "        # Gene embeddings for the cell line\n",
    "        gene_embedding = self.gene_embeddings[cell_line_id]  # [245, 231]\n",
    "        pathway_graph = self.pathway_graphs  # Pathway graphs\n",
    "\n",
    "        # Substructure embeddings for pathways\n",
    "        substructure_embedding = self.substructure_embeddings[drug_id].repeat(num_pathways, 1)  # [1, 170]\n",
    "        drug_graph = self.drug_graphs[drug_id]  # Drug graphs\n",
    "\n",
    "        # Get the label for the cell line-drug pair\n",
    "        label = self.labels[cell_line_id, drug_id]  # Scalar\n",
    "\n",
    "        return {\n",
    "            'gene_embedding': gene_embedding,  # [245, 231]\n",
    "            'pathway_graph': pathway_graph,                     # List of PyTorch Geometric Data objects\n",
    "            'substructure_embedding': substructure_embedding,  # [245, 170]\n",
    "            'drug_graph': drug_graph,  # PyTorch Geometric Data object\n",
    "            'label': label  # Scalar\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    gene_embeddings = []\n",
    "    substructure_embeddings = []\n",
    "    drug_graphs = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in batch:\n",
    "        gene_embeddings.append(item['gene_embedding'])\n",
    "        substructure_embeddings.append(item['substructure_embedding'])\n",
    "        drug_graphs.append(item['drug_graph'])\n",
    "        labels.append(item['label'])\n",
    "\n",
    "    pathway_graph = batch[0]['pathway_graph'] \n",
    "    pathway_batch = Batch.from_data_list(pathway_graph)\n",
    "    drug_batch = Batch.from_data_list(drug_graphs)\n",
    "\n",
    "    return {\n",
    "        'gene_embeddings': torch.stack(gene_embeddings),  # [batch_size, num_pathways, num_genes]\n",
    "        'pathway_graphs': pathway_batch,  \n",
    "        'substructure_embeddings': torch.stack(substructure_embeddings),  # [batch_size, num_pathways, num_substructures]\n",
    "        'drug_graphs': drug_batch, # PyTorch Geometric Batch\n",
    "        'labels': torch.tensor(labels, dtype=torch.float32)  # [batch_size]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터셋 초기화\n",
    "train_data = torch.load('train_dataset.pt')\n",
    "train_dataset = DrugResponseDataset(\n",
    "    gene_embeddings=train_data['gene_embeddings'],\n",
    "    pathway_graphs=train_data['pathway_graphs'],\n",
    "    substructure_embeddings=train_data['substructure_embeddings'],\n",
    "    drug_graphs=train_data['drug_graphs'],\n",
    "    labels=train_data['labels'],\n",
    "    sample_indices=train_data['sample_indices'],\n",
    ")\n",
    "\n",
    "\n",
    "val_data = torch.load('val_dataset.pt')\n",
    "val_dataset = DrugResponseDataset(\n",
    "    gene_embeddings=val_data['gene_embeddings'],\n",
    "    pathway_graphs=val_data['pathway_graphs'],\n",
    "    substructure_embeddings=val_data['substructure_embeddings'],\n",
    "    drug_graphs=val_data['drug_graphs'],\n",
    "    labels=val_data['labels'],\n",
    "    sample_indices=val_data['sample_indices'],\n",
    ")\n",
    "\n",
    "\n",
    "test_data = torch.load('test_dataset.pt')\n",
    "test_dataset = DrugResponseDataset(\n",
    "    gene_embeddings=test_data['gene_embeddings'],\n",
    "    pathway_graphs=test_data['pathway_graphs'],\n",
    "    substructure_embeddings=test_data['substructure_embeddings'],\n",
    "    drug_graphs=test_data['drug_graphs'],\n",
    "    labels=test_data['labels'],\n",
    "    sample_indices=test_data['sample_indices'],\n",
    ")\n",
    "\n",
    "# DataLoader 초기화\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 데이터 확인\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "for batch in train_loader:\n",
    "    print(f\"Batch gene embeddings: {batch['gene_embeddings'].shape}\")  # [batch_size, num_pathways, num_genes]\n",
    "    print(f\"Batch pathway_graphs: {batch['pathway_graphs']}\")  \n",
    "    print(f\"Batch substructure embeddings: {batch['substructure_embeddings'].shape}\")   # [batch_size, num_pathways, num_substructures]\n",
    "    print(f\"Batch drug graphs: {batch['drug_graphs']}\")  # PyTorch Geometric Batch\n",
    "    print(f\"Batch labels: {batch['labels'].shape}\")  # [batch_size]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Embedding Layer\n",
    "### - GeneEmbeddingLayer : FloatTensor -> Linear\n",
    "### - SubstructureEmbeddingLayer : IntTensor -> nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE_EMBEDDING_DIM = 128\n",
    "SUBSTRUCTURE_EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "FINAL_DIM = 64\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneEmbeddingLayer(nn.Module):\n",
    "    # In)  [BATCH_SIZE, NUM_PATHWAYS, NUM_GENES] \n",
    "    # Out) [BATCH_SIZE, NUM_PATHWAYS, NUM_GENES, GENE_EMBEDDING_DIM]\n",
    "\n",
    "    def __init__(self, num_genes, embedding_dim=GENE_EMBEDDING_DIM):\n",
    "        super(GeneEmbeddingLayer, self).__init__()\n",
    "        self.linear = nn.Linear(1, embedding_dim)  \n",
    "        self.num_genes = num_genes\n",
    "        \n",
    "    def forward(self, gene_values):\n",
    "        gene_values = gene_values.view(-1, 1) # [BATCH_SIZE * NUM_PATHWAYS * NUM_GENES, 1]\n",
    "        embedded_values = self.linear(gene_values)  # [BATCH_SIZE * NUM_PATHWAYS * NUM_GENES, GENE_EMBEDDING_DIM]\n",
    "        return embedded_values.view(-1, num_pathways, num_genes, GENE_EMBEDDING_DIM) \n",
    "\n",
    "class SubstructureEmbeddingLayer(nn.Module):\n",
    "    # In)  [BATCH_SIZE, NUM_PATHWAYS, NUM_SUBSTRUCTURES]\n",
    "    # Out) [BATCH_SIZE, NUM_PATHWAYS, NUM_SUBSTRUCTURES, SUBSTRUCTURES_EMBEDDING_DIM]\n",
    "    \n",
    "    def __init__(self, num_substructures, embedding_dim=SUBSTRUCTURE_EMBEDDING_DIM):\n",
    "        super(SubstructureEmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_substructures, embedding_dim) # [NUM_SUBSTRUCTURES, SUBSTRUCTURES_EMBEDDING_DIM]\n",
    "\n",
    "    def forward(self, substructure_indices):\n",
    "        return self.embedding(substructure_indices) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.query_layer = nn.Linear(query_dim, query_dim)  \n",
    "        self.key_layer = nn.Linear(key_dim, query_dim)      \n",
    "        self.value_layer = nn.Linear(key_dim, query_dim)    \n",
    "\n",
    "    def forward(self, query_embeddings, key_embeddings):\n",
    "        query = self.query_layer(query_embeddings) \n",
    "        key = self.key_layer(key_embeddings)        \n",
    "        value = self.value_layer(key_embeddings)   \n",
    "\n",
    "        # Attention Scores\n",
    "        attention_scores = torch.matmul(query, key.transpose(-1, -2))  \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)        \n",
    "\n",
    "        # Apply Attention\n",
    "        attended_embeddings = torch.matmul(attention_weights, value)  \n",
    "        \n",
    "        return attended_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (2) Graph Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathwayGraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(PathwayGraphEmbedding, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, gene_emb, pathway_graph):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gene_emb: Tensor of shape [BATCH_SIZE, NUM_GENES, 128]\n",
    "            pathway_graph: PyTorch Geometric Data object (single graph)\n",
    "        Returns:\n",
    "            graph_embeddings: Tensor of shape [BATCH_SIZE, NUM_PATHWAYS, EMBEDDING_DIM]\n",
    "        \"\"\"\n",
    "        batch_size = gene_emb.size(0)  # Extract batch size\n",
    "        global_ids = pathway_graph.global_ids  # Node IDs to update\n",
    "\n",
    "        # Repeat the graph `batch_size` times (데이터 자체에서 graph를 복사해서 넣어주면 삭제 가능하나 메모리 상황 보고 결정)\n",
    "        repeated_graphs = [pathway_graph.clone() for _ in range(batch_size)]\n",
    "        batched_graph = Batch.from_data_list(repeated_graphs)\n",
    "\n",
    "        # Update node features for all graphs\n",
    "        node_features = gene_emb[:, global_ids, :]  # Shape: [BATCH_SIZE, NUM_NODES, 128]\n",
    "        node_features = node_features.reshape(-1, node_features.size(-1))  # Flatten for all graphs\n",
    "        batched_graph.x = node_features  # Assign to graph\n",
    "\n",
    "        # GCN layers\n",
    "        x = F.relu(self.conv1(batched_graph.x, batched_graph.edge_index))\n",
    "        x = self.conv2(x, batched_graph.edge_index)\n",
    "\n",
    "        # Global mean pooling to aggregate graph embeddings\n",
    "        graph_embeddings = global_mean_pool(x, batched_graph.batch)  # Shape: [BATCH_SIZE, EMBEDDING_DIM]\n",
    "        \n",
    "        return graph_embeddings\n",
    "\n",
    "\n",
    "class DrugGraphEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(DrugGraphEmbedding, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, drug_graph, drug_graph_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            drug_graph (Batch): Batched PyTorch Geometric Data object.\n",
    "            drug_graph_embedding (Tensor): [BATCH_SIZE, NUM_PATHWAYS, NUM_SUBSTRUCTURES, EMBEDDING_DIM]\n",
    "        \"\"\"\n",
    "        all_node_features = []\n",
    "        updated_node_features = torch.mean(drug_graph_embedding, dim=1)  # [BATCH_SIZE, NUM_SUBSTRUCTURES, SUBSTRUCTURE_EMBEDDING_DIM]\n",
    "\n",
    "        # Batch Loop\n",
    "        for batch_idx in range(updated_node_features.size(0)):  \n",
    "            # Get global IDs and node indices\n",
    "            global_ids = drug_graph[batch_idx].global_ids  \n",
    "            node_indices = torch.where(drug_graph.batch == batch_idx)[0]\n",
    "\n",
    "            # Ensure global_ids and node_indices match in length\n",
    "            assert len(global_ids) == len(node_indices), \"Mismatch between global IDs and node indices length\"\n",
    "\n",
    "            # Update node features for the current batch\n",
    "            node_features = torch.zeros((len(node_indices), updated_node_features.size(-1)), device=updated_node_features.device)\n",
    "            for local_idx, global_id in enumerate(global_ids):\n",
    "                if global_id < updated_node_features.size(1):\n",
    "                    node_features[local_idx] = updated_node_features[batch_idx, global_id]\n",
    "\n",
    "            # Append the current batch's node features to the list\n",
    "            all_node_features.append(node_features)\n",
    "\n",
    "        # updated node features from all batches\n",
    "        new_node_features = torch.cat(all_node_features, dim=0)  # Shape: [TOTAL_NUM_NODES, EMBEDDING_DIM]\n",
    "        drug_graph.x = new_node_features\n",
    "\n",
    "        # Ensure edge_index is not empty\n",
    "        if drug_graph.edge_index.size(1) == 0:\n",
    "            num_nodes = drug_graph.num_nodes\n",
    "            drug_graph.edge_index = torch.stack([torch.arange(num_nodes), torch.arange(num_nodes)], dim=0)\n",
    "            print(\"Warning: Edge index was empty. Added self-loops.\")\n",
    "\n",
    "        # GCN layers\n",
    "        x = self.conv1(drug_graph.x, drug_graph.edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, drug_graph.edge_index)\n",
    "\n",
    "        # Perform global mean pooling\n",
    "        graph_embedding = global_mean_pool(x, drug_graph.batch)  # Shape: [BATCH_SIZE, HIDDEN_DIM]\n",
    "        \n",
    "        return graph_embedding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) DrugResponseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DrugResponseModel(nn.Module):\n",
    "    def __init__(self, num_genes, num_substructures, hidden_dim, final_dim):\n",
    "        super(DrugResponseModel, self).__init__()\n",
    "        self.gene_embedding_layer = GeneEmbeddingLayer(num_genes, GENE_EMBEDDING_DIM)\n",
    "        self.substructure_embedding_layer = SubstructureEmbeddingLayer(num_substructures, SUBSTRUCTURE_EMBEDDING_DIM)\n",
    "        \n",
    "        self.Gene2Sub_cross_attention = CrossAttention(query_dim=GENE_EMBEDDING_DIM, key_dim=SUBSTRUCTURE_EMBEDDING_DIM)\n",
    "        self.Sub2Gene_cross_attention = CrossAttention(query_dim=SUBSTRUCTURE_EMBEDDING_DIM, key_dim=GENE_EMBEDDING_DIM)\n",
    "\n",
    "        self.pathway_graph = PathwayGraphEmbedding(GENE_EMBEDDING_DIM, hidden_dim)\n",
    "        self.drug_graph = DrugGraphEmbedding(SUBSTRUCTURE_EMBEDDING_DIM, hidden_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(GENE_EMBEDDING_DIM + hidden_dim, final_dim)\n",
    "        self.fc2 = nn.Linear(final_dim, OUTPUT_DIM)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, gene_embeddings, pathway_graphs, substructure_embeddings, drug_graphs):\n",
    "        # Gene and Substructure Embeddings\n",
    "        substructure_embeddings = substructure_embeddings.int() \n",
    "        gene_embeddings = self.gene_embedding_layer(gene_embeddings)  # [Batch, Pathway, Gene, Embedding_dim]\n",
    "        substructure_embeddings = self.substructure_embedding_layer(substructure_embeddings)  \n",
    "\n",
    "        # Cross Attention (Vectorized)\n",
    "        gene_query = self.Gene2Sub_cross_attention(gene_embeddings, substructure_embeddings)  # [Batch, Pathway, Gene, Embedding_dim]\n",
    "        sub_query = self.Sub2Gene_cross_attention(substructure_embeddings, gene_embeddings)  # [Batch, Pathway, Substructure, Embedding_dim]\n",
    "\n",
    "        # Graph Embedding Loop for Pathways\n",
    "        # IN) 하나의 Pathway에 대한 Gene Embedding [Batch, Gene, Embedding_dim]\n",
    "        #                        Pathway Graph [Pytorch Geometric Data]\n",
    "        # OUT) Pathway Graph Embedding [Batch, Embedding_dim] → [Batch, Pathway, Embedding_dim]\n",
    "        pathway_graph_embeddings = torch.stack([\n",
    "            self.pathway_graph(gene_query[:, i, :, :], pathway_graphs[i])\n",
    "            for i in range(gene_query.size(1))\n",
    "        ], dim=1)\n",
    "\n",
    "\n",
    "        # Combine embeddings\n",
    "        final_pathway_embedding = torch.mean(pathway_graph_embeddings, dim=1)  # [Batch, Embedding_dim]\n",
    "        final_drug_embedding = self.drug_graph(drug_graphs, sub_query)  # [Batch, hidden_dim]\n",
    "\n",
    "        # Concatenate and Predict\n",
    "        combined_embedding = torch.cat((final_pathway_embedding, final_drug_embedding), dim=-1)  # [B, Dg + H]\n",
    "\n",
    "        x = self.fc1(combined_embedding)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrugResponseModel(num_genes, num_substructures, HIDDEN_DIM, FINAL_DIM)\n",
    "model = model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# Training Loop with Validation and Metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train_preds = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        gene_embeddings = batch['gene_embeddings'].to(device)\n",
    "        pathway_graphs =  batch['pathway_graphs'].to(device)\n",
    "        substructure_embeddings = batch['substructure_embeddings'].to(device)\n",
    "        drug_graphs = batch['drug_graphs'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(gene_embeddings, pathway_graphs, substructure_embeddings, drug_graphs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Accuracy Calculation\n",
    "        preds = (outputs.squeeze() > 0.5).long()  # Binary classification threshold\n",
    "        correct_train_preds += (preds == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train_preds / total_train_samples\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val_preds = 0\n",
    "    total_val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            gene_embeddings = batch['gene_embeddings'].to(device)\n",
    "            pathway_graphs =  batch['pathway_graphs'].to(device)\n",
    "            substructure_embeddings = batch['substructure_embeddings'].to(device)\n",
    "            drug_graphs = batch['drug_graphs'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(gene_embeddings, pathway_graphs, substructure_embeddings, drug_graphs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Accuracy Calculation\n",
    "            preds = (outputs.squeeze() > 0.5).long()\n",
    "            correct_val_preds += (preds == labels).sum().item()\n",
    "            total_val_samples += labels.size(0)\n",
    "\n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val_preds / total_val_samples\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Phase\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "correct_test_preds = 0\n",
    "total_test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        gene_embeddings = batch['gene_embeddings'].to(device)\n",
    "        pathway_graphs =  batch['pathway_graphs'].to(device)\n",
    "        substructure_embeddings = batch['substructure_embeddings'].to(device)\n",
    "        drug_graphs = batch['drug_graphs'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(gene_embeddings, pathway_graphs, substructure_embeddings, drug_graphs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        # Accuracy Calculation\n",
    "        preds = (outputs.squeeze() > 0.5).long()  # Binary classification threshold\n",
    "        correct_test_preds += (preds == labels).sum().item()\n",
    "        total_test_samples += labels.size(0)\n",
    "\n",
    "test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test_preds / total_test_samples\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Train and Validation Loss\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss per Epoch')\n",
    "plt.show()\n",
    "\n",
    "# Plot Train and Validation Accuracy\n",
    "plt.figure()\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy per Epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drTrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
